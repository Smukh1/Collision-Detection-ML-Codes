{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce722bd",
   "metadata": {},
   "source": [
    "# Directly importing a small chunk of dataset from the website and making a time series problem out of it with 4 features (including the lagged/previous velocities) and 1 lable (velocity).\n",
    "# Introduced a new coloum of previous velocity by shifting the target variable to create a lag (storing the velocity of previous time step).\n",
    "# Tried to use an autoregressive LSTM model and make some future velocity predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a427086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '5,6'\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5,6\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "79740486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Using seaborn for pairplot.\n",
    "!pip install -q seaborn\n",
    "!pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "524f77c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c1535ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining columns to use\n",
    "columns_to_use = [\"global_x\", \"global_y\", \"v_vel\", \"v_acc\", \"global_time\"] #using just 4 of them\n",
    "\n",
    "# Defining chunk size for reading data\n",
    "chunk_size = 100\n",
    "\n",
    "# Initializing an empty list to store data chunks\n",
    "data_chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(\"https://data.transportation.gov/resource/8ect-6jqj.csv\", \n",
    "                         chunksize=chunk_size, usecols=columns_to_use):\n",
    "    data_chunks.append(chunk)\n",
    "\n",
    "# Concatenate data chunks into a single DataFrame\n",
    "velocity_dataset = pd.concat(data_chunks, ignore_index=True)\n",
    "\n",
    "# trajectory_dataset = pd.read_csv(\n",
    "#     \"https://data.transportation.gov/resource/8ect-6jqj.csv\")\n",
    "\n",
    "#   names=[\"Vehicle_ID\", \"Frame_Id\", \"Total_Frames\", \"Global_Time\", \"Local_X\",\n",
    "#            \"Local_Y\", \"Global_X\", \"Global_Y\", \"v_length\", \"v_Width\", \"v_Vel\", \n",
    "#            \"v_Acc\", \"Lane_ID\", \"O_Zone\", \"D_Zone\", \"Int_ID\", \"Section_ID\", \"Direction\",\n",
    "#            \"Movement\", \"Preceding\", \"Following\", \"Space_Headway\", \"Time_Headway\", \"Location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f0247052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocity_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "577aa4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_time</th>\n",
       "      <th>global_x</th>\n",
       "      <th>global_y</th>\n",
       "      <th>v_vel</th>\n",
       "      <th>v_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1163368300</td>\n",
       "      <td>2230502.921</td>\n",
       "      <td>1375532.938</td>\n",
       "      <td>33.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1163368200</td>\n",
       "      <td>2230503.114</td>\n",
       "      <td>1375537.934</td>\n",
       "      <td>33.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1163368100</td>\n",
       "      <td>2230502.731</td>\n",
       "      <td>1375540.951</td>\n",
       "      <td>33.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1163368000</td>\n",
       "      <td>2230502.906</td>\n",
       "      <td>1375544.692</td>\n",
       "      <td>33.96</td>\n",
       "      <td>10.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1163051100</td>\n",
       "      <td>2230518.568</td>\n",
       "      <td>1375546.762</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-4.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_time     global_x     global_y  v_vel  v_acc\n",
       "0   1163368300  2230502.921  1375532.938  33.96   0.00\n",
       "1   1163368200  2230503.114  1375537.934  33.96   0.00\n",
       "2   1163368100  2230502.731  1375540.951  33.96   0.00\n",
       "3   1163368000  2230502.906  1375544.692  33.96  10.82\n",
       "4   1163051100  2230518.568  1375546.762   0.25  -4.89"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocity_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa5988bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_dataset_sorted = velocity_dataset.sort_values(by='global_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bdfcbcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_time</th>\n",
       "      <th>global_x</th>\n",
       "      <th>global_y</th>\n",
       "      <th>v_vel</th>\n",
       "      <th>v_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1163034800</td>\n",
       "      <td>2230519.322</td>\n",
       "      <td>1375566.277</td>\n",
       "      <td>17.29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>1163034900</td>\n",
       "      <td>2230519.899</td>\n",
       "      <td>1375568.256</td>\n",
       "      <td>17.29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1163035000</td>\n",
       "      <td>2230519.957</td>\n",
       "      <td>1375569.755</td>\n",
       "      <td>17.29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1163035100</td>\n",
       "      <td>2230519.535</td>\n",
       "      <td>1375571.773</td>\n",
       "      <td>17.29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>1163035200</td>\n",
       "      <td>2230520.612</td>\n",
       "      <td>1375573.733</td>\n",
       "      <td>17.29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1163849900</td>\n",
       "      <td>2230532.048</td>\n",
       "      <td>1375568.927</td>\n",
       "      <td>25.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1163850000</td>\n",
       "      <td>2230532.204</td>\n",
       "      <td>1375571.494</td>\n",
       "      <td>25.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>1163850000</td>\n",
       "      <td>2230520.798</td>\n",
       "      <td>1375569.938</td>\n",
       "      <td>37.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>1163850100</td>\n",
       "      <td>2230532.360</td>\n",
       "      <td>1375574.060</td>\n",
       "      <td>25.71</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>1163850100</td>\n",
       "      <td>2230521.053</td>\n",
       "      <td>1375573.669</td>\n",
       "      <td>37.39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     global_time     global_x     global_y  v_vel  v_acc\n",
       "434   1163034800  2230519.322  1375566.277  17.29    0.0\n",
       "503   1163034900  2230519.899  1375568.256  17.29    0.0\n",
       "553   1163035000  2230519.957  1375569.755  17.29    0.0\n",
       "710   1163035100  2230519.535  1375571.773  17.29    0.0\n",
       "949   1163035200  2230520.612  1375573.733  17.29    0.0\n",
       "..           ...          ...          ...    ...    ...\n",
       "528   1163849900  2230532.048  1375568.927  25.71    0.0\n",
       "643   1163850000  2230532.204  1375571.494  25.71    0.0\n",
       "563   1163850000  2230520.798  1375569.938  37.39    0.0\n",
       "966   1163850100  2230532.360  1375574.060  25.71    0.0\n",
       "944   1163850100  2230521.053  1375573.669  37.39    0.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocity_dataset_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ae33f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the target variable to create a lag\n",
    "velocity_dataset_sorted['v_vel_lagged'] = velocity_dataset_sorted['v_vel'].shift(1)\n",
    "\n",
    "# Drop the first row since it will have NaN in the lagged column\n",
    "velocity_dataset_sorted = velocity_dataset_sorted.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ebe1b1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_time</th>\n",
       "      <th>global_x</th>\n",
       "      <th>global_y</th>\n",
       "      <th>v_vel</th>\n",
       "      <th>v_acc</th>\n",
       "      <th>v_vel_lagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>1163034900</td>\n",
       "      <td>2230519.899</td>\n",
       "      <td>1375568.256</td>\n",
       "      <td>17.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1163035000</td>\n",
       "      <td>2230519.957</td>\n",
       "      <td>1375569.755</td>\n",
       "      <td>17.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1163035100</td>\n",
       "      <td>2230519.535</td>\n",
       "      <td>1375571.773</td>\n",
       "      <td>17.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>1163035200</td>\n",
       "      <td>2230520.612</td>\n",
       "      <td>1375573.733</td>\n",
       "      <td>17.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1163036300</td>\n",
       "      <td>2230519.819</td>\n",
       "      <td>1375553.248</td>\n",
       "      <td>25.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1163849900</td>\n",
       "      <td>2230532.048</td>\n",
       "      <td>1375568.927</td>\n",
       "      <td>25.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1163850000</td>\n",
       "      <td>2230532.204</td>\n",
       "      <td>1375571.494</td>\n",
       "      <td>25.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>1163850000</td>\n",
       "      <td>2230520.798</td>\n",
       "      <td>1375569.938</td>\n",
       "      <td>37.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>1163850100</td>\n",
       "      <td>2230532.360</td>\n",
       "      <td>1375574.060</td>\n",
       "      <td>25.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>1163850100</td>\n",
       "      <td>2230521.053</td>\n",
       "      <td>1375573.669</td>\n",
       "      <td>37.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     global_time     global_x     global_y  v_vel  v_acc  v_vel_lagged\n",
       "503   1163034900  2230519.899  1375568.256  17.29    0.0         17.29\n",
       "553   1163035000  2230519.957  1375569.755  17.29    0.0         17.29\n",
       "710   1163035100  2230519.535  1375571.773  17.29    0.0         17.29\n",
       "949   1163035200  2230520.612  1375573.733  17.29    0.0         17.29\n",
       "99    1163036300  2230519.819  1375553.248  25.79    0.0         17.29\n",
       "..           ...          ...          ...    ...    ...           ...\n",
       "528   1163849900  2230532.048  1375568.927  25.71    0.0         37.39\n",
       "643   1163850000  2230532.204  1375571.494  25.71    0.0         25.71\n",
       "563   1163850000  2230520.798  1375569.938  37.39    0.0         25.71\n",
       "966   1163850100  2230532.360  1375574.060  25.71    0.0         37.39\n",
       "944   1163850100  2230521.053  1375573.669  37.39    0.0         25.71\n",
       "\n",
       "[999 rows x 6 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocity_dataset_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9beea861",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [\"global_x\", \"global_y\", \"v_acc\", \"v_vel_lagged\"]\n",
    "output_labels = [\"v_vel\"]\n",
    "\n",
    "input_dataset = velocity_dataset_sorted[input_features]\n",
    "output_dataset = velocity_dataset_sorted[output_labels]\n",
    "\n",
    "# Split the dataset into training and test sets (80-20 split)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(input_dataset, output_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Print the shape of training and test sets\n",
    "# print(\"Train Features Shape:\", train_features.shape)\n",
    "# print(\"Train Labels Shape:\", train_labels.shape)\n",
    "# print(\"Test Features Shape:\", test_features.shape)\n",
    "# print(\"Test Labels Shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bb27ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Normalizer Mean:  [[2230521.8   1375565.5        -0.306      10.321]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the features\n",
    "feature_normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "feature_normalizer.adapt(np.array(train_features))\n",
    "print(\"Feature Normalizer Mean: \", feature_normalizer.mean.numpy())\n",
    "\n",
    "# Normalize the training and test features\n",
    "train_features_normalized = feature_normalizer(np.array(train_features))\n",
    "test_features_normalized = feature_normalizer(np.array(test_features))\n",
    "\n",
    "# Prepare the input and output for LSTM\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# Create training data\n",
    "for i in range(1, len(train_features_normalized)):\n",
    "    X_train.append(train_features_normalized[i-1])\n",
    "    y_train.append(train_labels.iloc[i])\n",
    "\n",
    "# Create testing data\n",
    "for i in range(1, len(test_features_normalized)):\n",
    "    X_test.append(test_features_normalized[i-1])\n",
    "    y_test.append(test_labels.iloc[i])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "34d33735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in predictions: 0\n",
      "NaNs in predictions: 0\n",
      "NaNs in predictions: 0\n",
      "NaNs in predictions: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in training and testing data\n",
    "print(f\"NaNs in predictions: {np.isnan(X_train).sum()}\")\n",
    "print(f\"NaNs in predictions: {np.isnan(X_test).sum()}\")\n",
    "print(f\"NaNs in predictions: {np.isnan(y_train).sum()}\")\n",
    "print(f\"NaNs in predictions: {np.isnan(y_test).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d2a9f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #normailizing the output layer\n",
    "# label_normalizer=layers.Normalization(axis=-1)\n",
    "# label_normalizer.adapt(train_labels)\n",
    "# print(label_normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d5758335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features for LSTM [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3a7f1327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 4s 24ms/step - loss: 258.0149 - val_loss: 286.3500\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 255.0126 - val_loss: 281.0601\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 247.8183 - val_loss: 266.2862\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 230.2858 - val_loss: 229.4812\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 199.7767 - val_loss: 186.9572\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 173.4201 - val_loss: 167.5521\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 161.3892 - val_loss: 166.7090\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 158.3603 - val_loss: 167.1086\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 157.0652 - val_loss: 167.2262\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 155.9527 - val_loss: 167.9726\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 156.0672 - val_loss: 167.7253\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 155.0180 - val_loss: 168.2912\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 154.8201 - val_loss: 167.3448\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 153.9742 - val_loss: 168.2658\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 153.8040 - val_loss: 168.1272\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 153.3678 - val_loss: 168.2921\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 153.2305 - val_loss: 167.6689\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 152.9906 - val_loss: 168.0198\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 152.9449 - val_loss: 168.1639\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 152.9883 - val_loss: 168.7588\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 152.6808 - val_loss: 168.4474\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 151.8988 - val_loss: 168.5917\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 152.1729 - val_loss: 168.8156\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 151.7895 - val_loss: 168.7144\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 151.6024 - val_loss: 168.4459\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 151.2937 - val_loss: 168.8385\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 151.3815 - val_loss: 169.4962\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 151.5414 - val_loss: 169.1462\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 151.0686 - val_loss: 168.8813\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 151.2318 - val_loss: 169.0320\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 151.1764 - val_loss: 169.6050\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 151.2186 - val_loss: 169.1788\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 150.5753 - val_loss: 169.4677\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 150.5370 - val_loss: 169.5453\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 150.5720 - val_loss: 169.4215\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 150.4657 - val_loss: 169.6244\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 150.4398 - val_loss: 169.4231\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 150.1837 - val_loss: 169.5861\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 150.1044 - val_loss: 169.6210\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 150.0577 - val_loss: 169.7505\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 149.8397 - val_loss: 169.3896\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 149.7000 - val_loss: 169.6920\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 149.7892 - val_loss: 169.8259\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 149.6812 - val_loss: 169.5424\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 149.5089 - val_loss: 170.1445\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 149.7704 - val_loss: 169.9203\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 149.7846 - val_loss: 169.8858\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 149.2864 - val_loss: 169.9410\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 149.4789 - val_loss: 169.6256\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 149.2365 - val_loss: 170.1401\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 149.2573 - val_loss: 170.3879\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 149.3060 - val_loss: 170.2455\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 149.1494 - val_loss: 169.5625\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 148.8301 - val_loss: 170.0078\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 148.9030 - val_loss: 170.2625\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 148.8343 - val_loss: 170.2499\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 148.8804 - val_loss: 170.2148\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 148.7418 - val_loss: 169.8462\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 148.8524 - val_loss: 170.0431\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 148.4988 - val_loss: 170.1503\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 148.5595 - val_loss: 170.3548\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 148.4789 - val_loss: 170.6223\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 148.7627 - val_loss: 170.3337\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 148.3396 - val_loss: 169.8867\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 148.2939 - val_loss: 170.0228\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 148.6729 - val_loss: 170.4983\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 148.1651 - val_loss: 170.0180\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 148.2219 - val_loss: 170.0611\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 147.9511 - val_loss: 170.1383\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 147.9876 - val_loss: 170.5359\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 147.9664 - val_loss: 170.1282\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 148.0557 - val_loss: 169.9916\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 148.0837 - val_loss: 169.6883\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 147.7481 - val_loss: 170.1599\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.6987 - val_loss: 170.0994\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.8589 - val_loss: 170.0859\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.8676 - val_loss: 169.7511\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 147.6667 - val_loss: 170.5132\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.4668 - val_loss: 170.0547\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 147.5667 - val_loss: 169.9830\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 147.4731 - val_loss: 170.2134\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.3809 - val_loss: 170.1125\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.6364 - val_loss: 170.2904\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.5007 - val_loss: 170.1839\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 147.1718 - val_loss: 169.7795\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.5092 - val_loss: 169.8767\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.7758 - val_loss: 170.0843\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 146.8158 - val_loss: 170.3183\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.0526 - val_loss: 169.8401\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 147.2714 - val_loss: 170.3551\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 147.1747 - val_loss: 170.1187\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 146.8171 - val_loss: 170.2141\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 146.7394 - val_loss: 170.0508\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 146.9441 - val_loss: 169.8392\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 146.9530 - val_loss: 170.0575\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 146.9386 - val_loss: 169.9073\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 146.6773 - val_loss: 170.0383\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 146.8845 - val_loss: 170.3255\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 146.6345 - val_loss: 169.9760\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 146.6086 - val_loss: 169.8238\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "lstm_model = tf.keras.Sequential()\n",
    "# Add the first LSTM layer with relu activation and input shape\n",
    "lstm_model.add(tf.keras.layers.LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "\n",
    "# Add a second LSTM layer with relu activation\n",
    "lstm_model.add(tf.keras.layers.LSTM(64, activation='relu', return_sequences=False))  # return_sequences=False by default for last LSTM layer\n",
    "\n",
    "# # Add a Dense layer with relu activation\n",
    "# lstm_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "lstm_model.add(tf.keras.layers.Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# # Early stopping callback\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# # Fit the model with early stopping\n",
    "# history = lstm_model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "history = lstm_model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# divide the dataset into 3 parts and then al last use the 3rd part to test the dataset (validataion dataset)\n",
    "# do it after testing the model with validation dataset\n",
    "#validtion = split(xtrain,ytrain, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4cf82c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN detected in prediction at step 163\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and use previous predictions as inputs for the next prediction\n",
    "predictions = []\n",
    "current_input = X_test[0].reshape(1, 1, X_test.shape[2])  # Start with the first test sample\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    current_pred = lstm_model.predict(current_input, verbose=0)\n",
    "    if np.isnan(current_pred).any():\n",
    "        print(f\"NaN detected in prediction at step {i}\")\n",
    "        break\n",
    "    predictions.append(current_pred[0])\n",
    "    \n",
    "    # Update the current input with the new prediction\n",
    "    current_input = np.array([np.append(current_input[0][0][1:], current_pred[0])]).reshape(1, 1, -1)\n",
    "\n",
    "# Convert predictions to the correct shape\n",
    "predictions = np.array(predictions).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3bb353f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in predictions: 0\n",
      "Infs in predictions: 1\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs and infs in predictions\n",
    "nan_count = np.isnan(predictions).sum()\n",
    "inf_count = np.isinf(predictions).sum()\n",
    "\n",
    "print(f\"NaNs in predictions: {nan_count}\")\n",
    "print(f\"Infs in predictions: {inf_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "60c194b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of y_test before filtering NaNs: 199\n",
      "Length of predictions before filtering NaNs: 163\n",
      "Length of y_test_filtered after filtering NaNs: 162\n",
      "Length of predictions_filtered after filtering NaNs: 162\n"
     ]
    }
   ],
   "source": [
    "# Debugging prints to check lengths before filtering NaNs and Infs\n",
    "print(f\"Length of y_test before filtering NaNs: {len(y_test)}\")\n",
    "print(f\"Length of predictions before filtering NaNs: {len(predictions)}\")\n",
    "\n",
    "# # Create combined mask to filter out NaNs and Infs\n",
    "# mask = ~(np.isnan(predictions) | np.isinf(predictions))\n",
    "\n",
    "# # Filter y_test and predictions arrays\n",
    "# y_test_filtered = y_test[mask]\n",
    "# predictions_filtered = predictions[mask]\n",
    "\n",
    "# Filter out NaNs and infs from predictions\n",
    "mask = ~np.isnan(predictions).flatten() & ~np.isinf(predictions).flatten()\n",
    "predictions = predictions[mask]\n",
    "\n",
    "# Ensure y_test_cleaned matches the length of predictions\n",
    "y_test_filtered = y_test[:len(predictions)]\n",
    "predictions_filtered = predictions[:len(predictions)]\n",
    "\n",
    "# Debugging prints to check lengths after filtering NaNs and Infs\n",
    "print(f\"Length of y_test_filtered after filtering NaNs: {len(y_test_filtered)}\")\n",
    "print(f\"Length of predictions_filtered after filtering NaNs: {len(predictions_filtered)}\")\n",
    "\n",
    "# Ensure y_test_filtered and predictions_filtered are reshaped properly\n",
    "y_test_reshaped = y_test_filtered.reshape(-1, 1)\n",
    "predictions_reshaped = predictions_filtered.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "df4af953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5.29230234156925e+74\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_reshaped, predictions)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "21968ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABPZElEQVR4nO3deZzNdf//8ecxy5lhNsuYMYwla6IhJFSIK8olUrZLWZJSVLjaXF1EXYh+KpUrKS4qa1eo0OIrSwvZmoSa0FjCWJIZM8PMmPP+/XGuORyzfMY4M2eWx/12O7dzzufzPp/zOu9xY55en8/72IwxRgAAAACAXJXzdgEAAAAAUNwRnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAebLZbJowYYK3y/C6Dh06qEOHDq7nBw4ckM1m07x587xW0+Uur7GkmTBhgmw2m7fLAIAcEZwAoAj9+9//ls1mU+vWrQt8jKNHj2rChAmKjY31XGHF3Pr162Wz2Vw3Pz8/XXPNNRo4cKB+++03b5d3Rb777jtNmDBBZ86c8XYpAIAr4OvtAgCgLFmwYIFq166tLVu2aN++fapXr94VH+Po0aOaOHGiateurWbNmnm+yGLs8ccfV6tWrZSRkaEdO3Zo9uzZWrVqlX766SdFRUUVaS21atXSuXPn5Ofnd0Wv++677zRx4kQNHjxYYWFhhVMcAMDj6DgBQBGJj4/Xd999p1deeUXh4eFasGCBt0sqcW655Rbdd999GjJkiN544w39v//3/3T69GnNnz8/19ekpKQUSi02m00BAQHy8fEplOMDAIoXghMAFJEFCxaoYsWK6tatm+69995cg9OZM2c0evRo1a5dW3a7XTVq1NDAgQN16tQprV+/Xq1atZIkDRkyxHXqWtZ1NrVr19bgwYOzHfPya1/S09M1fvx4tWjRQqGhoapQoYJuueUWrVu37oo/1/Hjx+Xr66uJEydm2xcXFyebzaY333xTkpSRkaGJEyeqfv36CggIUOXKlXXzzTdrzZo1V/y+knTbbbdJcoZS6eI1Mnv27NHf/vY3VaxYUTfffLNr/AcffKAWLVooMDBQlSpVUr9+/XT48OFsx509e7bq1q2rwMBA3Xjjjfr666+zjcntGqdffvlFffr0UXh4uAIDA9WwYUM999xzrvqeeuopSVKdOnVcP78DBw4USo05adKkiTp27Jhtu8PhUPXq1XXvvffm6zgjR45UUFCQUlNTs+3r37+/IiMjlZmZ6dr22Wef6ZZbblGFChUUHBysbt26affu3fl6LwAoDghOAFBEFixYoF69esnf31/9+/fX3r17tXXrVrcxycnJuuWWW/TGG2/o9ttv14wZMzR8+HD98ssv+v3333XttdfqhRdekCQ99NBDev/99/X+++/r1ltvvaJakpKS9O6776pDhw6aOnWqJkyYoJMnT6pLly5XfO1URESE2rdvr6VLl2bbt2TJEvn4+Kh3796SnMFh4sSJ6tixo958800999xzqlmzpnbs2HFF75ll//79kqTKlSu7be/du7dSU1M1efJkDRs2TJI0adIkDRw4UPXr19crr7yiUaNGae3atbr11lvdrjeaM2eOHn74YUVGRmratGlq166d7rrrrhzDy+V27typ1q1b66uvvtKwYcM0Y8YM9ezZU59++qkkqVevXurfv78k6dVXX3X9/MLDw4usxr59+2rjxo1KSEhw2/7NN9/o6NGj6tevn+Uxso6TkpKiVatWuW1PTU3Vp59+qnvvvdfVjXv//ffVrVs3BQUFaerUqRo3bpz27Nmjm2++2S00AkCxZgAAhW7btm1GklmzZo0xxhiHw2Fq1KhhnnjiCbdx48ePN5LMsmXLsh3D4XAYY4zZunWrkWT+85//ZBtTq1YtM2jQoGzb27dvb9q3b+96fuHCBZOWluY25s8//zQRERHmgQcecNsuyTz//PN5fr63337bSDI//fST2/bGjRub2267zfU8JibGdOvWLc9j5WTdunVGkpk7d645efKkOXr0qFm1apWpXbu2sdlsZuvWrcYYY55//nkjyfTv39/t9QcOHDA+Pj5m0qRJbtt/+ukn4+vr69qenp5uqlatapo1a+Y2P7NnzzaS3OYwPj4+28/h1ltvNcHBwebgwYNu75P1szPGmJdfftlIMvHx8YVeY07i4uKMJPPGG2+4bX/00UdNUFCQSU1NzfP1l36m6tWrm3vuucdt+9KlS40ks3HjRmOMMWfPnjVhYWFm2LBhbuMSEhJMaGio2/asnx8AFEd0nACgCCxYsEARERGuU6RsNpv69u2rxYsXu53O9NFHHykmJkZ33313tmN4cplmHx8f+fv7S3KeonX69GlduHBBLVu2LFD3p1evXvL19dWSJUtc23bt2qU9e/aob9++rm1hYWHavXu39u7dW6C6H3jgAYWHhysqKkrdunVTSkqK5s+fr5YtW7qNGz58uNvzZcuWyeFwqE+fPjp16pTrFhkZqfr167tOUdy2bZtOnDih4cOHu+ZHkgYPHqzQ0NA8azt58qQ2btyoBx54QDVr1nTbl5+fXVHUKEkNGjRQs2bN3H5WmZmZ+u9//6vu3bsrMDDQ8hhZn6l3795avXq1kpOTXduXLFmi6tWru06RXLNmjc6cOaP+/fu7fS4fHx+1bt26QKeHAoA3lOngtHHjRnXv3l1RUVGy2WxasWLFFb0+Li5OHTt2VEREhAICAnTNNdfon//8pzIyMtzGvfbaa2rYsKECAwMVHR2t0aNH6/z58x78JACKs8zMTC1evFgdO3ZUfHy89u3bp3379ql169Y6fvy41q5d6xq7f/9+NWnSpEjqmj9/vq6//nrXtUbh4eFatWqVEhMTr/hYVapUUadOndxO11uyZIl8fX3Vq1cv17YXXnhBZ86cUYMGDdS0aVM99dRT2rlzZ77fZ/z48VqzZo2++uor7dy5U0ePHtX999+fbVydOnXcnu/du1fGGNWvX1/h4eFut59//lknTpyQJB08eFCSVL9+fbfXZy1/npesZdEL+vMrihqz9O3bV99++62OHDkiybnc+4kTJ9xCbn6Pc+7cOX3yySeSnKearl69Wr1793aFxayQfNttt2X7XF9++aXrcwFAcVemlyNPSUlRTEyMHnjgAbd/2PPLz89PAwcO1A033KCwsDD9+OOPGjZsmBwOhyZPnixJWrhwoZ599lnNnTtXbdu21a+//qrBgwfLZrPplVde8fRHAlAMffXVVzp27JgWL16sxYsXZ9u/YMEC3X777R55r9w6G5mZmW6rv33wwQcaPHiwevbsqaeeekpVq1aVj4+PpkyZ4rpu6Er169dPQ4YMUWxsrJo1a6alS5eqU6dOqlKlimvMrbfeqv379+vjjz/Wl19+qXfffVevvvqqZs2apQcffNDyPZo2barOnTtbjru8a+JwOGSz2fTZZ5/luApeUFBQPj5h4SrKGvv27auxY8fqww8/1KhRo7R06VKFhoaqa9euV3Scm266SbVr19bSpUv1t7/9TZ9++qnOnTvnFsAcDock53VOkZGR2Y7h61umfxUBUIKU6b+t7rjjDt1xxx257k9LS9Nzzz2nRYsW6cyZM2rSpImmTp3qWpnqmmuucfvfvVq1amn9+vVuKxt99913ateunf72t79Jcq541b9/f33//feF86EAFDsLFixQ1apVNXPmzGz7li1bpuXLl2vWrFkKDAxU3bp1tWvXrjyPl9dpXxUrVszxi1UPHjzo9vfVf//7X11zzTVatmyZ2/Gef/75fHyinPXs2VMPP/yw6xSwX3/9VWPHjs02rlKlShoyZIiGDBmi5ORk3XrrrZowYUK+glNB1a1bV8YY1alTRw0aNMh1XK1atSQ5uyRZK/ZJztUA4+PjFRMTk+trs+a3oD+/oqgxS506dXTjjTdqyZIlGjlypJYtW6aePXvKbrdbvvZyffr00YwZM5SUlKQlS5aodu3auummm9w+lyRVrVo1X6EXAIqrMn2qnpWRI0dq06ZNWrx4sXbu3KnevXura9euuZ6bv2/fPn3++edq3769a1vbtm21fft2bdmyRZLzVI7Vq1frzjvvLJLPAMC7zp07p2XLlumvf/2r7r333my3kSNH6uzZs65Tne655x79+OOPWr58ebZjGWMkSRUqVJCkHANS3bp1tXnzZqWnp7u2rVy5Mttqa1kdjaxjStL333+vTZs2FfizhoWFqUuXLlq6dKkWL14sf39/9ezZ023MH3/84fY8KChI9erVU1paWoHfNz969eolHx8fTZw40e0zS845yKqrZcuWCg8P16xZs9zmcN68eTnO96XCw8N16623au7cuTp06FC298iS28+vKGq8VN++fbV582bNnTtXp06duuLT9C49TlpamubPn6/PP/9cffr0cdvfpUsXhYSEaPLkydlOZZec14YBQIngpUUpih1JZvny5a7nBw8eND4+PubIkSNu4zp16mTGjh3rtq1NmzbGbrcbSeahhx4ymZmZbvtnzJhh/Pz8jK+vr5Fkhg8fXmifA0DxsnjxYiPJrFixIsf9mZmZJjw83HTv3t0Y41yBrHHjxsbHx8cMGzbMzJo1y0yePNncdNNNJjY21hjjXFUtLCzMNGzY0Lz77rtm0aJF5rfffjPGGPP5558bSaZjx47mrbfeMk8++aSJjIw0devWdVttbe7cuUaSueuuu8zbb79tnn32WRMWFmauu+46U6tWLbcalY9V9bJ88MEHRpIJDg52faZLVa1a1fTp08dMnTrVvPPOO+bhhx82NpvNPPbYY3keN2tVvQ8//DDPcVmrsp08eTLbvilTphhJpm3btmbatGnmrbfeMk8//bSpX7++efnll13jslYIbNeunXn99dfN6NGjTVhYmLnmmmssV9WLjY01QUFBpnLlymbs2LFm9uzZ5h//+IeJiYlxjdmyZYuRZO68807z3nvvmUWLFpnk5ORCqTEvhw8fNjabzQQHB5tKlSqZ9PT0fL0uJ/Xq1TPBwcFGktm+fXu2/QsWLDDlypUzTZo0Mf/617/M22+/bZ577jnTrFkzM2LECNc4VtUDUJzxt9P/XB6cVq5caSSZChUquN18fX1Nnz593F576NAhs3v3brNw4UJTvXp1M3XqVNe+devWmYiICPPOO++YnTt3mmXLlpno6GjzwgsvFNVHA+BF3bt3NwEBASYlJSXXMYMHDzZ+fn7m1KlTxhhj/vjjDzNy5EhTvXp14+/vb2rUqGEGDRrk2m+MMR9//LFp3Lix6z9kLv3lffr06aZ69erGbrebdu3amW3btmVbjtzhcJjJkyebWrVqGbvdbpo3b25WrlxpBg0adFXBKSkpyQQGBhpJ5oMPPsi2/1//+pe58cYbTVhYmAkMDDSNGjUykyZNsvyl3RPByRhjPvroI3PzzTe7/k5v1KiRGTFihImLi3Mb9+9//9vUqVPH2O1207JlS7Nx48Zsc5hTcDLGmF27dpm7777bhIWFmYCAANOwYUMzbtw4tzEvvviiqV69uilXrly2pck9WaOVdu3aGUnmwQcfzPdrcvLcc88ZSaZevXq5jlm3bp3p0qWLCQ0NNQEBAaZu3bpm8ODBZtu2ba4xBCcAxZnNmMvOByijbDabli9f7jqtZMmSJRowYIB2796d7SLdoKCgHC9wlZwXXD/00EM6e/asfHx8dMstt+imm27Syy+/nG1McnKyypXjbEkAAACguCvTi0PkpXnz5srMzNSJEyd0yy235Pt1DodDGRkZcjgc8vHxUWpqarZwlNO1BQAAAACKrzIdnJKTk7Vv3z7X8/j4eMXGxqpSpUpq0KCBBgwYoIEDB2r69Olq3ry5Tp48qbVr1+r6669Xt27dtGDBAvn5+alp06ay2+3atm2bxo4dq759+8rPz0+S1L17d73yyitq3ry5WrdurX379mncuHHq3r17jsvNAgDgbadPn3ZbeOJyPj4+Cg8PL8KKAMD7yvSpeuvXr1fHjh2zbR80aJDmzZunjIwM/etf/9J7772nI0eOqEqVKrrppps0ceJENW3aVEuWLNG0adP066+/yhijWrVq6b777tPo0aMVEBAgSbpw4YImTZqk999/X0eOHFF4eLi6d++uSZMmKSwsrIg/MQAA1jp06KANGzbkur9WrVo6cOBA0RUEAMVAmQ5OAAAgu+3bt+vPP//MdX9gYKDatWtXhBUBgPcRnAAAAADAAku6AQAAAICFMrc4hMPh0NGjRxUcHCybzebtcgAAAAB4iTFGZ8+eVVRUlOXXBJW54HT06FFFR0d7uwwAAAAAxcThw4dVo0aNPMeUueAUHBwsyTk5ISEhXq4GAAAAgLckJSUpOjralRHyUuaCU9bpeSEhIQQnAAAAAPm6hIfFIQAAAADAAsEJAAAAACwQnAAAAADAQpm7xik/jDG6cOGCMjMzvV0KCsjHx0e+vr4sOQ8AAACPIDhdJj09XceOHVNqaqq3S8FVKl++vKpVqyZ/f39vlwIAAIASjuB0CYfDofj4ePn4+CgqKkr+/v50LEogY4zS09N18uRJxcfHq379+pZfaAYAAADkheB0ifT0dDkcDkVHR6t8+fLeLgdXITAwUH5+fjp48KDS09MVEBDg7ZIAAABQgvHf8DmgO1E68HMEAACAp/CbJQAAAABYIDgBAAAAgAWCEwqdzWbTihUrvF0GAAAAUGAEp1Jm06ZN8vHxUbdu3a7odbVr19Zrr71WOEUBAAAAJRzBqZSZM2eOHnvsMW3cuFFHjx71djkAAABAqUBwsmCMUWr6Ba/cjDFXVGtycrKWLFmiRx55RN26ddO8efPc9n/66adq1aqVAgICVKVKFd19992SpA4dOujgwYMaPXq0bDab67urJkyYoGbNmrkd47XXXlPt2rVdz7du3aq//OUvqlKlikJDQ9W+fXvt2LHjiucZAAAAKM74HicL5zIy1Xj8F1557z0vdFF5//z/iJYuXapGjRqpYcOGuu+++zRq1CiNHTtWNptNq1at0t13363nnntO7733ntLT07V69WpJ0rJlyxQTE6OHHnpIw4YNu6Iaz549q0GDBumNN96QMUbTp0/XnXfeqb179yo4OPiKjgUAAAAUVwSnUmTOnDm67777JEldu3ZVYmKiNmzYoA4dOmjSpEnq16+fJk6c6BofExMjSapUqZJ8fHwUHBysyMjIK3rP2267ze357NmzFRYWpg0bNuivf/3rVX4iAAAAoHggOFkI9PPRnhe6eO298ysuLk5btmzR8uXLJUm+vr7q27ev5syZow4dOig2NvaKu0n5cfz4cf3zn//U+vXrdeLECWVmZio1NVWHDh3y+HsBAACgBNq5U4qKkqpU8XYlV4XgZMFms13R6XLeMmfOHF24cEFRUVGubcYY2e12vfnmmwoMDLziY5YrVy7bdVYZGRluzwcNGqQ//vhDM2bMUK1atWS329WmTRulp6cX7IMAAACg9PjtNykmRrr1VmnDBm9Xc1VYHKIUuHDhgt577z1Nnz5dsbGxrtuPP/6oqKgoLVq0SNdff73Wrl2b6zH8/f2VmZnpti08PFwJCQlu4Sk2NtZtzLfffqvHH39cd955p6677jrZ7XadOnXKo58PAAAAJdThw877vXu9W4cHFP9WCiytXLlSf/75p4YOHarQ0FC3fffcc4/mzJmjl19+WZ06dVLdunXVr18/XbhwQatXr9Yzzzwjyfk9Ths3blS/fv1kt9tVpUoVdejQQSdPntS0adN077336vPPP9dnn32mkJAQ1/Hr16+v999/Xy1btlRSUpKeeuqpAnW3AAAAUAplna109qx36/AAOk6lwJw5c9S5c+dsoUlyBqdt27apUqVK+vDDD/XJJ5+oWbNmuu2227RlyxbXuBdeeEEHDhxQ3bp1FR4eLkm69tpr9e9//1szZ85UTEyMtmzZoieffDLbe//555+64YYbdP/99+vxxx9X1apVC/cDAwAAoGTICk7JyZLD4d1arpLNXOmXBZVwSUlJCg0NVWJiolvnRJLOnz+v+Ph41alTRwEBAV6qEJ7CzxMAAMDLPvlE6tHD+TgxUbrs929vyysbXI6OEwAAAIDCcenCYklJ3qvDAwhOAAAAAArHpcGphF/nRHACAAAAUDgITgAAAABg4dLv9uRUPQAAAADIAR0nAAAAALDA4hAAAAAAYIGOEwAAAABYoOMEAAAAABboOKGsGjx4sHr27Ol63qFDB40aNarI61i/fr1sNpvOnDlT5O8NAACAfCI4obgZPHiwbDabbDab/P39Va9ePb3wwgu6cOFCob7vsmXL9OKLL+ZrLGEHAACgjClFp+r5ersAeE7Xrl31n//8R2lpaVq9erVGjBghPz8/jR071m1cenq6/P39PfKelSpV8shxAAAAUArRcfKMKVOmqFWrVgoODlbVqlXVs2dPxcXFWb7uww8/VKNGjRQQEKCmTZtq9erVhVekMVJKinduxlxRqXa7XZGRkapVq5YeeeQRde7cWZ988onr9LpJkyYpKipKDRs2lCQdPnxYffr0UVhYmCpVqqQePXrowIEDruNlZmZqzJgxCgsLU+XKlfX000/LXFbT5afqpaWl6ZlnnlF0dLTsdrvq1aunOXPm6MCBA+rYsaMkqWLFirLZbBo8eLAkyeFwaMqUKapTp44CAwMVExOj//73v27vs3r1ajVo0ECBgYHq2LGjW50AAAAopkpRx8mrwWnDhg0aMWKENm/erDVr1igjI0O33367UlJScn3Nd999p/79+2vo0KH64Ycf1LNnT/Xs2VO7du0qnCJTU6WgIO/cUlOvqvTAwECl/+/bmteuXau4uDitWbNGK1euVEZGhrp06aLg4GB9/fXX+vbbbxUUFKSuXbu6XjN9+nTNmzdPc+fO1TfffKPTp09r+fLleb7nwIEDtWjRIr3++uv6+eef9fbbbysoKEjR0dH66KOPJElxcXE6duyYZsyYIckZoN977z3NmjVLu3fv1ujRo3Xfffdpw4YNkpwBr1evXurevbtiY2P14IMP6tlnn72quQEAAEARKEUdJ5li5MSJE0aS2bBhQ65j+vTpY7p16+a2rXXr1ubhhx/O13skJiYaSSYxMTHbvnPnzpk9e/aYc+fOXdyYnGyMs/dT9Lfk5PxNnDFm0KBBpkePHsYYYxwOh1mzZo2x2+3mySefNIMGDTIREREmLS3NNf799983DRs2NA6Hw7UtLS3NBAYGmi+++MIYY0y1atXMtGnTXPszMjJMjRo1XO9jjDHt27c3TzzxhDHGmLi4OCPJrFmzJsca161bZySZP//807Xt/Pnzpnz58ua7775zGzt06FDTv39/Y4wxY8eONY0bN3bb/8wzz2Q71uVy/HkCAACg6AwbdvF324YNvV1NNnllg8sVq2ucEhMTJeV93cymTZs0ZswYt21dunTRihUrchyflpamtLQ01/OkK20Rli8vJSdf2Ws8pXz5Kxq+cuVKBQUFKSMjQw6HQ3/72980YcIEjRgxQk2bNnW7runHH3/Uvn37FBwc7HaM8+fPa//+/UpMTNSxY8fUunVr1z5fX1+1bNky2+l6WWJjY+Xj46P27dvnu+Z9+/YpNTVVf/nLX9y2p6enq3nz5pKkn3/+2a0OSWrTpk2+3wMAAABeUoo6TsUmODkcDo0aNUrt2rVTkyZNch2XkJCgiIgIt20RERFKSEjIcfyUKVM0ceLEghdms0kVKhT89UWoY8eOeuutt+Tv76+oqCj5+l788Va47DMkJyerRYsWWrBgQbbjhIeHF+j9AwMDr/g1yf8LpatWrVL16tXd9tnt9gLVAQAAgGKiFAWnYrMc+YgRI7Rr1y4tXrzYo8cdO3asEhMTXbfDhw979PjFSYUKFVSvXj3VrFnTLTTl5IYbbtDevXtVtWpV1atXz+0WGhqq0NBQVatWTd9//73rNRcuXND27dtzPWbTpk3lcDhc1yZdLqvjlZmZ6drWuHFj2e12HTp0KFsd0dHRkqRrr71WW7ZscTvW5s2b854MAAAAeN//rp2X5AxODof3arlKxSI4jRw5UitXrtS6detUo0aNPMdGRkbq+PHjbtuOHz+uyMjIHMfb7XaFhIS43SANGDBAVapUUY8ePfT1118rPj5e69ev1+OPP67ff/9dkvTEE0/opZde0ooVK/TLL7/o0UcfzfM7mGrXrq1BgwbpgQce0IoVK1zHXLp0qSSpVq1astlsWrlypU6ePKnk5GQFBwfrySef1OjRozV//nzt379fO3bs0BtvvKH58+dLkoYPH669e/fqqaeeUlxcnBYuXKh58+YV9hQBAADgal3acZKcK0eXUF4NTsYYjRw5UsuXL9dXX32lOnXqWL6mTZs2Wrt2rdu2NWvWcM3LFSpfvrw2btyomjVrqlevXrr22ms1dOhQnT9/3hUu//73v+v+++/XoEGD1KZNGwUHB+vuu+/O87hvvfWW7r33Xj366KNq1KiRhg0b5lolsXr16po4caKeffZZRUREaOTIkZKkF198UePGjdOUKVN07bXXqmvXrlq1apXrz0PNmjX10UcfacWKFYqJidGsWbM0efLkQpwdAAAAeMTlwakEL0luM7ld6V8EHn30US1cuFAff/yx67uFJCk0NNR1vczAgQNVvXp1TZkyRZJzOfL27dvrpZdeUrdu3bR48WJNnjxZO3bsyPPaqCxJSUkKDQ1VYmJitu7T+fPnFR8frzp16iggIMCDnxTewM8TAADAy7p0kb788uLzn3+WGjXyXj2XySsbXM6rHae33npLiYmJ6tChg6pVq+a6LVmyxDXm0KFDOnbsmOt527ZttXDhQs2ePdv1RakrVqzIV2gCAAAAUIRKUcfJq6vq5afZtX79+mzbevfurd69exdCRQAAAAA85vLgVIJX1isWi0MAAAAAKIUITgAAAABgoRSdqkdwyoEX18uAB/FzBAAA8LKs4BQW5ryn41Q6+Pn5SZJSU1O9XAk8IevnmPVzBQAAQBHLCk6VKzvvS3DHyauLQxQ3Pj4+CgsL04kTJyQ5v+vIZrN5uSpcKWOMUlNTdeLECYWFhcnHx8fbJQEAAJRNWcGpUiVp//4S3XEiOF0mMjJSklzhCSVXWFiY6+cJAAAAL6DjVHrZbDZVq1ZNVatWVcblF7OhxPDz86PTBAAA4G2XdpwkOk6lkY+PD794AwAAAFejFAUnFocAAAAAUDjS0533peBUPYITAAAAgMJBxwkAAAAALJSixSEITgAAAAA8zxjpwgXnYzpOAAAAAJCDrNAkXew4EZwAAAAA4BKXfrXPpR0nY7xTz1UiOAEAAADwvEuDU1bHyRgpJcU79VwlghMAAAAAz7s0OIWGSuX+Fz1K6AIRBCcAAAAAnpcVnMqVc95CQpzPS+h1TgQnAAAAAJ6XFZz8/Jz3wcHOezpOAAAAAPA/lwcnOk4AAAAAcJncOk4EJwAAAAD4H07VAwAAAAALnKoHAAAAABbS0533dJwAAAAAIBd0nAAAAADAAtc4AQAAAIAFOk4AAAAAYIHlyAEAAADAQlZw8vd33nOqHgAAAABchlP1AAAAAMACi0MAAAAAgAU6TgAAAABggY4TAAAAAFjIreOUnCwZ452argLBCQAAAIDn5dZxcjik1FTv1HQVCE4AAAAAPO/y4FS+vFTuf/GjBJ6uR3ACAAAA4Hnp6c77rOBks5XoL8ElOAEAAADwvMs7TlKJXiCC4AQAAADA83IKTiV4SXKCEwAAAADPy6vjRHACAAAAAOXdceJUPQAAAADQxeDk739xGx0nAAAAALgEHScAAAAAsMA1TgAAAABggeXIAQAAAMACy5EDAAAAgAVO1QMAAAAACywOAQAAAAAW6DgBAAAAgAU6TgAAAABgIT3deU/HCQAAAABywXLkAAAAAGDBajlyY4q+pqtAcAIAAADgeXl1nBwO6dy5oq/pKhCcAAAAAHheTsGpQgXJZnM+LmGn6xGcAAAAAHheVnDy97+4zWYrsQtEEJwAAAAAeF5OHSepxC5JTnACAAAA4Hm5BacS2nHy9XYBAAAAAEqh3ILTggXOU/bq1Sv6mq4CwQkAAACA5+UWnJo3L/paPIBT9QAAAAB4Xm7BqYQiOAEAAADwPIITAAAAAFggOAEAAABAHjIzJYfD+ZjgBAAAAAA5yOo2SQQnAAAAAMgRwQkAAAAALBCcAAAAAMDCpcHJt3R8dSzBCQAAAIBnXbqins3m3Vo8hOAEAAAAwLNK2VLkEsEJAAAAgKcRnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACwQnAAAAADAAsEJAAAAACykpzvvCU4AAAAAkAs6TgAAAABggeAEAAAAABYITgAAAABgISs4+ft7tw4PIjgBAAAA8Cw6TgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITp61ceNGde/eXVFRUbLZbFqxYkWe49evXy+bzZbtlpCQUDQFAwAAALBGcPKslJQUxcTEaObMmVf0uri4OB07dsx1q1q1aiFVCAAAAOCKpac770tRcPL15pvfcccduuOOO674dVWrVlVYWJjnCwIAAABw9eg4FQ/NmjVTtWrV9Je//EXffvttnmPT0tKUlJTkdgMAAABQiAhO3lWtWjXNmjVLH330kT766CNFR0erQ4cO2rFjR66vmTJlikJDQ1236OjoIqwYAAAAKINKYXDy6ql6V6phw4Zq2LCh63nbtm21f/9+vfrqq3r//fdzfM3YsWM1ZswY1/OkpCTCEwAAAFCYCE7Fz4033qhvvvkm1/12u112u70IKwIAAADKuKzg5O/v3To8qESdqpeT2NhYVatWzdtlAAAAAMhCx8mzkpOTtW/fPtfz+Ph4xcbGqlKlSqpZs6bGjh2rI0eO6L333pMkvfbaa6pTp46uu+46nT9/Xu+++66++uorffnll976CAAAAAAuR3DyrG3btqljx46u51nXIg0aNEjz5s3TsWPHdOjQIdf+9PR0/f3vf9eRI0dUvnx5XX/99fq///s/t2MAAAAA8LJSGJxsxhjj7SKKUlJSkkJDQ5WYmKiQkBBvlwMAAACUPrfdJq1bJy1aJPXr5+1qcnUl2aDEX+MEAAAAoJgphR0nghMAAAAAzyI4AQAAAIAFghMAAAAAWCA4AQAAAICF9HTnPcEJAAAAAHJBxwkAAAAALBCcAAAAAMACwQkAAAAALGQFJ39/79bhQQQnAAAAAJ5FxwkAAAAALBCcAAAAAMACwQkAAAAA8mCMdOGC8zHBCQAAAABykBWaJIITAAAAAOQo6zQ9ieAEAAAAADkiOAEAAACABYITAAAAAFjICk7lyjlvpUTp+SQAAAAAvC893XlfirpNEsEJAAAAgCeVwu9wkghOAAAAADyJ4AQAAAAAFghOAAAAAGAhKzj5+3u3Dg8jOAEAAADwHDpOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGCB4AQAAAAAFghOAAAAAGAhPd15T3ACAAAAgFzQcQIAAAAACwQnAAAAALCQFZz8/b1bh4cRnAAAAAB4Dh0nAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAACwQnAAAAALBAcAIAAAAAC+npznuCEwAAAADkgo4TAAAAAFggOAEAAACAhazg5O/v3To8jOAEAAAAwHPoOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACABYITAAAAAFggOAEAAACAhfR05z3BCQAAAAByQccJAAAAACwQnAAAAADAAsEJAAAAAPKQmSkZ43zs7+/dWjyM4AQAAADAM7K6TRIdJwAAAADIEcEJAAAAACwQnAAAAADAwqXBycfHe3UUAt/8DhwzZky+D/rKK68UqBgAAAAAJdilK+rZbN6txcPyHZx++OGHfI2zlbIJAgAAAJBPpXQpcukKgtO6desKsw4AAAAAJV0pDk5XdY3Tvn379MUXX+jcuXOSJJO1ZjsAAACAsofg5O6PP/5Qp06d1KBBA9155506duyYJGno0KH6+9//7tECAQAAAJQQBCd3o0ePlp+fnw4dOqTy5cu7tvft21eff/65x4oDAAAAUIKkpzvvS2Fwyvc1Tpf68ssv9cUXX6hGjRpu2+vXr6+DBw96pDAAAAAAJQwdJ3cpKSlunaYsp0+flt1uv+qiAAAAAJRABCd3t9xyi9577z3Xc5vNJofDoWnTpqljx44eKw4AAABACZIVnPz9vVtHISjQqXrTpk1Tp06dtG3bNqWnp+vpp5/W7t27dfr0aX377beerhEAAABASUDHyV2TJk3066+/6uabb1aPHj2UkpKiXr166YcfflDdunU9XSMAAACAkqAUB6cCdZwkKTQ0VM8995wnawEAAABQkpXi4FSgjlO9evU0YcIE7d2719P1AAAAACipCE7uRowYoVWrVqlhw4Zq1aqVZsyYoYSEBE/XBgAAAKAkITi5Gz16tLZu3apffvlFd955p2bOnKno6GjdfvvtbqvtAQAAAChDCE45a9CggSZOnKhff/1VX3/9tU6ePKkhQ4Z4qjYAAAAAJUkpDk4FXhwiy5YtW7Rw4UItWbJESUlJ6t27tyfqAgAAAFDSEJzc/frrr1qwYIEWLVqk+Ph43XbbbZo6dap69eqloKAgT9cIAAAAoCQgOLlr1KiRWrVqpREjRqhfv36KiIjwdF0AAAAAShqCk7u4uDjVr1/fctyiRYt01113qUKFCgV5GwAAAAAlSXq6874UBqcCLQ6Rn9AkSQ8//LCOHz9ekLcAAAAAUNKU4o7TVa2qZ8UYk+f+jRs3qnv37oqKipLNZtOKFSssj7l+/XrdcMMNstvtqlevnubNm+eZYgEAAABcHYJT4UhJSVFMTIxmzpyZr/Hx8fHq1q2bOnbsqNjYWI0aNUoPPvigvvjii0KuFAAAAIClrODk7+/dOgrBVS9HfjXuuOMO3XHHHfkeP2vWLNWpU0fTp0+XJF177bX65ptv9Oqrr6pLly6FVSYAAACA/KDjVDxs2rRJnTt3dtvWpUsXbdq0KdfXpKWlKSkpye0GAAAAoBAQnIqHhISEbEufR0REKCkpSefOncvxNVOmTFFoaKjrFh0dXRSlAgAAAGUPwcndgw8+qPXr11uOq1Wrlvy8PGljx45VYmKi63b48GGv1gMAAACUWufPO+8DArxbRyEo0DVOJ0+eVNeuXRUeHq5+/frpvvvuU0xMTLZxu3btuuoCLxUZGZltefPjx48rJCREgYGBOb7GbrfLbrd7tA4AAAAAOcg6CyyX381LsgJ1nD7++GMdO3ZM48aN09atW3XDDTfouuuu0+TJk3XgwAEPl3hRmzZttHbtWrdta9asUZs2bQrtPQEAAADkUynuOBX4GqeKFSvqoYce0vr163Xw4EENHjxY77//vurVq5fvYyQnJys2NlaxsbGSnMuNx8bG6tChQ5Kcp9kNHDjQNX748OH67bff9PTTT+uXX37Rv//9by1dulSjR48u6McAAAAA4Cl0nHKXkZGhbdu26fvvv9eBAweyLd6Ql23btql58+Zq3ry5JGnMmDFq3ry5xo8fL0k6duyYK0RJUp06dbRq1SqtWbNGMTExmj59ut59912WIgcAAACKg1LccSrw9zitW7dOCxcu1EcffSSHw6FevXpp5cqVuu222/J9jA4dOsgYk+v+efPm5fiaH374oSAlAwAAAChMpbjjVKDgVL16dZ0+fVpdu3bV7Nmz1b17dxZgAAAAAMo6Ok7uJkyYoN69eyssLMzD5QAAAAAoseg4uRs2bJin6wAAAABQ0pXijtNVLw4BAAAAAJJKdceJ4AQAAADAM+g4AQAAAEAeHA4pLc35mI4TAAAAAOQgKzRJdJwAAAAAIEdZ1zdJdJwAAAAAIEdZwcnX13krZQhOAAAAAK5eKV4YQiI4AQAAAPCEUrwUuURwAgAAAOAJdJwAAAAAwAIdJwAAAACwQMcJAAAAACzQcQIAAAAAC3ScAAAAAMACHScAAAAAsEDHCQAAAAAs0HECAAAAAAt0nAAAAADAAh0nAAAAALBAxwkAAAAALNBxAgAAAAALdJwAAAAAwAIdJwAAAACwQMcJAAAAACzQcQIAAAAAC3ScAAAAAMACHScAAAAAsEDHCQAAAAAs0HECAAAAAAt0nAAAAADAAh0nAAAAALBAxwkAAAAALNBxAgAAAIA8GCOlpTkf03ECAAAAgBxknaYn0XECAAAAgBxdGpzoOAEAAABADrKub/Lxkfz8vFtLISE4AQAAALg6pXxFPYngBAAAAOBqlfIV9SSCEwAAAICrRccJAAAAACzQcQIAAAAAC3ScAAAAAMACHScAAAAAsJAVnOg4AQAAAEAusk7Vo+MEAAAAALngVD0AAAAAsMDiEAAAAABggY4TAAAAAFig4wQAAAAAFug4AQAAAIAFOk4AAAAAYIGOEwAAAABYoOMEAAAAABboOAEAAACABTpOAAAAAGCBjhMAAAAAWKDjBAAAAAAW6DgBAAAAgAU6TgAAAABggY4TAAAAAFig4wQAAAAAFug4AQAAAIAFOk4AAAAAkAdjLgYnOk4AAAAAkIO0tIuP6TgBAAAAQA6yrm+S6DgBAAAAQI6yTtMrV07y9fVuLYWI4AQAAACg4C5dUc9m824thYjgBAAAAKDgysCKehLBCQAAAMDVKAPf4SQRnAAAAABcDTpOAAAAAGCBjhMAAAAAWKDjBAAAAAAW6DgBAAAAgAU6TgAAAABggY4TAAAAAFig4wQAAAAAFug4AQAAAICFrOBExwkAAAAAcpF1qh4dJwAAAADIBR0nAAAAALBAxwkAAAAALNBxAgAAAAALdJwAAAAAwALLkQMAAACABb4AFwAAAAAs0HEqOjNnzlTt2rUVEBCg1q1ba8uWLbmOnTdvnmw2m9stoJSnWwAAAKDYouNUNJYsWaIxY8bo+eef144dOxQTE6MuXbroxIkTub4mJCREx44dc90OHjxYhBUDAAAAcKHjVDReeeUVDRs2TEOGDFHjxo01a9YslS9fXnPnzs31NTabTZGRka5bREREEVYMAAAAwIWOU+FLT0/X9u3b1blzZ9e2cuXKqXPnztq0aVOur0tOTlatWrUUHR2tHj16aPfu3bmOTUtLU1JSktsNAAAAgIfQcSp8p06dUmZmZraOUUREhBISEnJ8TcOGDTV37lx9/PHH+uCDD+RwONS2bVv9/vvvOY6fMmWKQkNDXbfo6GiPfw4AAACgzKLjVDy1adNGAwcOVLNmzdS+fXstW7ZM4eHhevvtt3McP3bsWCUmJrpuhw8fLuKKAQAAgFKsjHScfL355lWqVJGPj4+OHz/utv348eOKjIzM1zH8/PzUvHlz7du3L8f9drtddrv9qmsFAAAAcBlj6DgVBX9/f7Vo0UJr1651bXM4HFq7dq3atGmTr2NkZmbqp59+UrVq1QqrTAAAAAA5SUu7+JiOU+EaM2aMBg0apJYtW+rGG2/Ua6+9ppSUFA0ZMkSSNHDgQFWvXl1TpkyRJL3wwgu66aabVK9ePZ05c0Yvv/yyDh48qAcffNCbHwMAAAAoe7K6TVKp7zh5PTj17dtXJ0+e1Pjx45WQkKBmzZrp888/dy0YcejQIZUrd7Ex9ueff2rYsGFKSEhQxYoV1aJFC3333Xdq3Lixtz4CAAAAUDZlXd9Urpzk5+fdWgqZzRhjvF1EUUpKSlJoaKgSExMVEhLi7XIAAACAkis+XrrmGql8eSklxdvVXLEryQYlblU9AAAAAMVEGVlRTyI4AQAAACioMrKinkRwAgAAAFBQdJwAAAAAwAIdJwAAAACwQMcJAAAAACzQcQIAAAAAC3ScAAAAAOASqanS8OHS119f3FaGOk6+3i4AAAAAQAnw4YfS229LmzdLsbHObXScAAAAAOASv//uvP/xR+nkSefjMtRxIjgBAAAAsHb06MXH69Y57+k4AQAAAMAljh27+HjtWuc9HScAAAAAuMSlwemrr5z3dJwAAAAA4BKXBqd9+6RDh+g4AQAAAICLMReDU/Xqzvu1a+k4AQAAAIDL6dNSerrzcf/+zvtLgxMdJwAAAABlXla3qVIl6c47nY/pOAEAAADAJbKCU7VqUps2zg5TQsLFL8Kl4wQAAACgzMv6Dqdq1ZwhqV075/OsL8Wl4wQAAACgzMvqOEVFOe87dXLfT8cJAAAAQJl36al6UvbgRMcJAAAAQJl3eXC64QYpJOTifjpOAAAAAMq8y4OTr6/UocPF/XScAAAAAJR5WYtDZF3jJLmfrkfHCQAAAECZZkz2jpPkHpzKQMfJ19sFAAAAACjGkpIuftHtpcGpcWPntU4nTrhvL6UITgAAAAByl9VtCgmRype/uN1mk7ZskTIyJLvdO7UVIYITAAAAgNzldH1TFh8f560M4BonAAAAALnL6fqmMojgBAAAACB3BCdJBCcAAAAAeSE4SSI4AQAAAMhLXtc4lSEEJwAAAAC5o+MkieAEAAAAIC8EJ0kEJwAAAAB5IThJIjgBAAAAyE1ysnT2rPMx1zgBAAAAQA6yuk0VKkjBwd6txcsITgAAAAByxml6LgQnAAAAADkjOLkQnAAAAADkjO9wciE4AQAAAMgZHScXghMAAACAnBGcXAhOAAAAAHJGcHIhOAEAAADIWVZw4honghMAAACAXGQtDkHHieAEAAAAIAfnzklnzjgfE5wITgAAAABykJDgvLfbpbAwr5ZSHBCcAAAAAGR36fVNNpt3aykGCE4AAAAAsuP6JjcEJwAAAADZsRS5G4ITAAAAgOwITm4ITgAAAACy4zuc3BCcAAAAAGR35Ijzno6TJIITAAAAgJz88ovzvn5979ZRTBCcAAAAALhLSpIOH3Y+btzYu7UUEwQnAAAAAO5+/tl5X62aVLGid2spJghOAAAAANzt2eO8p9vkQnACAAAA4I7glA3BCQAAAIC73bud99dd5906ihGCEwAAAAB3dJyyITgBAAAAuCg5WTp40PmY4ORCcAIAAABwUdaKehERUuXK3q2lGCE4AQAAALiI0/RyRHACAAAAcBELQ+SI4AQAAADgIjpOOSI4AQAAALgoKzjRcXJDcAIAAADglJIixcc7H9NxckNwAgAAAOD0yy/O+/BwqUoV79ZSzBCcAAAAADhxml6uCE4AAAAAnLJW1OM0vWwITgAAAACcWFEvVwQnAAAAAE6cqpcrghMAAAAAKTVV+u0352M6TtkQnAAAAABIcXGSMc7V9KpW9XY1xQ7BCQAAAChrjHEuBJGefnEbC0PkieAEAAAAlDWvvio1aSLddNPF0/NYGCJPBCcAAACgLElOliZPdj7+4QepRQtp5UoWhrDg6+0CAAAAABSht96S/vhDqltXCg+XNm+WuneXAgKc++k45YiOEwAAAFBWpKZKL7/sfDxunLRhg/T4487n58877+k45YjgBAAAAJQVb78tnTwp1akj/e1vkr+/NGOGtHixFBTkvO6JFfVyRHACAAAAyoJz56Rp05yP//EPyc/v4r6+faWjR6WtWyWbzTv1FXNc4wQAAACUBXPmSAkJUs2a0sCB2fcHBxd9TSUIHScAAACgtEtLk156yfn42Wedp+jhihCcAAAAgNJu3jzpyBGpenXpgQe8XU2JRHACAAAASrNDh6Tx452Pn35astu9W08JRXACAAAASquUFKlHD+nECSkmRho2zNsVlVgEJwAAAKA0cjikwYOl2FjnF91+/LEUGOjtqkosghMAAABQGr34ovTf/zqXHV++XKpVy9sVlWgsRw4AAACUVH/+Kc2fL23Y4Fz4oVEj5+3wYWnCBOeYWbOkdu28WmZpUCw6TjNnzlTt2rUVEBCg1q1ba8uWLXmO//DDD9WoUSMFBASoadOmWr16dRFVCgAAABQDW7c6V8erXl0aPVpasUKaOVN67DHpL3+5uHLeqFGsouchXu84LVmyRGPGjNGsWbPUunVrvfbaa+rSpYvi4uJUtWrVbOO/++479e/fX1OmTNFf//pXLVy4UD179tSOHTvUpEkTL3wCAAAAwIOMkWw2921Hj0obNzo7S+vXS7/8cnFf06bSgAHO7tMvv0hxcdK+fdJf/yq9/HKRll6a2YwxxpsFtG7dWq1atdKbb74pSXI4HIqOjtZjjz2mZ599Ntv4vn37KiUlRStXrnRtu+mmm9SsWTPNmjXL8v2SkpIUGhqqxMREhYSEeO6DFID57Telb93m1Rry5N0/GnmjtoIrzvUV59qk4l1fca5NKt71FefapOJdH7UVXHGurzjXJhXv+oyR7cIFKSPjf7cL0oUM2VzPM6T0dCnjf9suOLfZEpOkUydlO3lKtlMnZTt7VsZulwICnDebTbaEBPe38vdX5r336sKwh+Ro0zZ70MopfBUzgX4+snm5xivJBl7tOKWnp2v79u0aO3asa1u5cuXUuXNnbdq0KcfXbNq0SWPGjHHb1qVLF61YsSLH8WlpaUpLS3M9T0pKuvrCPST9iy9lf/QRb5cBAACAYsaWlialpUmJiZKkTFs57Y64RltqXKct0U20uWZTJQUESZ8nS59/6eVqC2bPC11U3t/rJ8Dlm1crPXXqlDIzMxUREeG2PSIiQr9c2n68REJCQo7jEy5L4VmmTJmiiRMneqZgT6saoS01Gnu7imyMiuH/ThTD/zEprv/fZYrlXBXDmopfScVznopjTcXwz3hxVRznqnj+mfJ2BdkVz3kqhjV5u4AcZJbzUUY5X13w8dGFcr7KKOejCz6+unDJ9oxy/3vu46eMcj5K8Q/U6fKh+uN/t2R7efllXpD9QrrsmRnyv5ChA5WidNZewdsfr0wrORGvgMaOHevWoUpKSlJ0dLQXK7rIv1dPNene3dtlAAAAAEUu0M/H2yVcEa8GpypVqsjHx0fHjx932378+HFFRkbm+JrIyMgrGm+322W32z1TsIfZbLYS1Z4EAAAAyiqvLkfu7++vFi1aaO3ata5tDodDa9euVZs2bXJ8TZs2bdzGS9KaNWtyHQ8AAAAAV8vr7Y4xY8Zo0KBBatmypW688Ua99tprSklJ0ZAhQyRJAwcOVPXq1TVlyhRJ0hNPPKH27dtr+vTp6tatmxYvXqxt27Zp9uzZ3vwYAAAAAEoxrwenvn376uTJkxo/frwSEhLUrFkzff75564FIA4dOqRy5S42xtq2bauFCxfqn//8p/7xj3+ofv36WrFiBd/hBAAAAKDQeP17nIpacfoeJwAAAADecyXZwKvXOAEAAABASUBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsEBwAgAAAAALBCcAAAAAsODr7QKKmjFGkpSUlOTlSgAAAAB4U1YmyMoIeSlzwens2bOSpOjoaC9XAgAAAKA4OHv2rEJDQ/McYzP5iVeliMPh0NGjRxUcHCybzebtcpSUlKTo6GgdPnxYISEh3i6nVGFuCxfzW3iY28LF/BYe5rZwMb+Fh7ktXMV5fo0xOnv2rKKiolSuXN5XMZW5jlO5cuVUo0YNb5eRTUhISLH7g1RaMLeFi/ktPMxt4WJ+Cw9zW7iY38LD3Bau4jq/Vp2mLCwOAQAAAAAWCE4AAAAAYIHg5GV2u13PP/+87Ha7t0spdZjbwsX8Fh7mtnAxv4WHuS1czG/hYW4LV2mZ3zK3OAQAAAAAXCk6TgAAAABggeAEAAAAABYITgAAAABggeAEAAAAABYITl40c+ZM1a5dWwEBAWrdurW2bNni7ZJKnClTpqhVq1YKDg5W1apV1bNnT8XFxbmNOX/+vEaMGKHKlSsrKChI99xzj44fP+6liku2l156STabTaNGjXJtY34L7siRI7rvvvtUuXJlBQYGqmnTptq2bZtrvzFG48ePV7Vq1RQYGKjOnTtr7969Xqy45MjMzNS4ceNUp04dBQYGqm7dunrxxRd16XpIzG/+bdy4Ud27d1dUVJRsNptWrFjhtj8/c3n69GkNGDBAISEhCgsL09ChQ5WcnFyEn6J4ymtuMzIy9Mwzz6hp06aqUKGCoqKiNHDgQB09etTtGMxt7qz+7F5q+PDhstlseu2119y2M785y8/c/vzzz7rrrrsUGhqqChUqqFWrVjp06JBrf0n7HYLg5CVLlizRmDFj9Pzzz2vHjh2KiYlRly5ddOLECW+XVqJs2LBBI0aM0ObNm7VmzRplZGTo9ttvV0pKimvM6NGj9emnn+rDDz/Uhg0bdPToUfXq1cuLVZdMW7du1dtvv63rr7/ebTvzWzB//vmn2rVrJz8/P3322Wfas2ePpk+frooVK7rGTJs2Ta+//rpmzZql77//XhUqVFCXLl10/vx5L1ZeMkydOlVvvfWW3nzzTf3888+aOnWqpk2bpjfeeMM1hvnNv5SUFMXExGjmzJk57s/PXA4YMEC7d+/WmjVrtHLlSm3cuFEPPfRQUX2EYiuvuU1NTdWOHTs0btw47dixQ8uWLVNcXJzuuusut3HMbe6s/uxmWb58uTZv3qyoqKhs+5jfnFnN7f79+3XzzTerUaNGWr9+vXbu3Klx48YpICDANabE/Q5h4BU33nijGTFihOt5ZmamiYqKMlOmTPFiVSXfiRMnjCSzYcMGY4wxZ86cMX5+fubDDz90jfn555+NJLNp0yZvlVninD171tSvX9+sWbPGtG/f3jzxxBPGGOb3ajzzzDPm5ptvznW/w+EwkZGR5uWXX3ZtO3PmjLHb7WbRokVFUWKJ1q1bN/PAAw+4bevVq5cZMGCAMYb5vRqSzPLly13P8zOXe/bsMZLM1q1bXWM+++wzY7PZzJEjR4qs9uLu8rnNyZYtW4wkc/DgQWMMc3slcpvf33//3VSvXt3s2rXL1KpVy7z66quufcxv/uQ0t3379jX33Xdfrq8pib9D0HHygvT0dG3fvl2dO3d2bStXrpw6d+6sTZs2ebGyki8xMVGSVKlSJUnS9u3blZGR4TbXjRo1Us2aNZnrKzBixAh169bNbR4l5vdqfPLJJ2rZsqV69+6tqlWrqnnz5nrnnXdc++Pj45WQkOA2t6GhoWrdujVzmw9t27bV2rVr9euvv0qSfvzxR33zzTe64447JDG/npSfudy0aZPCwsLUsmVL15jOnTurXLly+v7774u85pIsMTFRNptNYWFhkpjbq+VwOHT//ffrqaee0nXXXZdtP/NbMA6HQ6tWrVKDBg3UpUsXVa1aVa1bt3Y7na8k/g5BcPKCU6dOKTMzUxEREW7bIyIilJCQ4KWqSj6Hw6FRo0apXbt2atKkiSQpISFB/v7+rn9gsjDX+bd48WLt2LFDU6ZMybaP+S243377TW+99Zbq16+vL774Qo888ogef/xxzZ8/X5Jc88ffEwXz7LPPql+/fmrUqJH8/PzUvHlzjRo1SgMGDJDE/HpSfuYyISFBVatWddvv6+urSpUqMd9X4Pz583rmmWfUv39/hYSESGJur9bUqVPl6+urxx9/PMf9zG/BnDhxQsnJyXrppZfUtWtXffnll7r77rvVq1cvbdiwQVLJ/B3C19sFAJ4yYsQI7dq1S9988423Syk1Dh8+rCeeeEJr1qxxOycZV8/hcKhly5aaPHmyJKl58+batWuXZs2apUGDBnm5upJv6dKlWrBggRYuXKjrrrtOsbGxGjVqlKKiophflEgZGRnq06ePjDF66623vF1OqbB9+3bNmDFDO3bskM1m83Y5pYrD4ZAk9ejRQ6NHj5YkNWvWTN99951mzZql9u3be7O8AqPj5AVVqlSRj49PtlVDjh8/rsjISC9VVbKNHDlSK1eu1Lp161SjRg3X9sjISKWnp+vMmTNu45nr/Nm+fbtOnDihG264Qb6+vvL19dWGDRv0+uuvy9fXVxEREcxvAVWrVk2NGzd223bttde6VhvKmj/+niiYp556ytV1atq0qe6//36NHj3a1Tllfj0nP3MZGRmZbfGjCxcu6PTp08x3PmSFpoMHD2rNmjWubpPE3F6Nr7/+WidOnFDNmjVd/8YdPHhQf//731W7dm1JzG9BValSRb6+vpb/zpW03yEITl7g7++vFi1aaO3ata5tDodDa9euVZs2bbxYWcljjNHIkSO1fPlyffXVV6pTp47b/hYtWsjPz89truPi4nTo0CHmOh86deqkn376SbGxsa5by5YtNWDAANdj5rdg2rVrl23p/F9//VW1atWSJNWpU0eRkZFuc5uUlKTvv/+euc2H1NRUlSvn/k+cj4+P639BmV/Pyc9ctmnTRmfOnNH27dtdY7766is5HA61bt26yGsuSbJC0969e/V///d/qly5stt+5rbg7r//fu3cudPt37ioqCg99dRT+uKLLyQxvwXl7++vVq1a5fnvXIn8Hc3bq1OUVYsXLzZ2u93MmzfP7Nmzxzz00EMmLCzMJCQkeLu0EuWRRx4xoaGhZv369ebYsWOuW2pqqmvM8OHDTc2aNc1XX31ltm3bZtq0aWPatGnjxapLtktX1TOG+S2oLVu2GF9fXzNp0iSzd+9es2DBAlO+fHnzwQcfuMa89NJLJiwszHz88cdm586dpkePHqZOnTrm3LlzXqy8ZBg0aJCpXr26WblypYmPjzfLli0zVapUMU8//bRrDPObf2fPnjU//PCD+eGHH4wk88orr5gffvjBtbJbfuaya9eupnnz5ub7778333zzjalfv77p37+/tz5SsZHX3Kanp5u77rrL1KhRw8TGxrr9O5eWluY6BnObO6s/u5e7fFU9Y5jf3FjN7bJly4yfn5+ZPXu22bt3r3njjTeMj4+P+frrr13HKGm/QxCcvOiNN94wNWvWNP7+/ubGG280mzdv9nZJJY6kHG//+c9/XGPOnTtnHn30UVOxYkVTvnx5c/fdd5tjx455r+gS7vLgxPwW3KeffmqaNGli7Ha7adSokZk9e7bbfofDYcaNG2ciIiKM3W43nTp1MnFxcV6qtmRJSkoyTzzxhKlZs6YJCAgw11xzjXnuuefcftlkfvNv3bp1Of5dO2jQIGNM/ubyjz/+MP379zdBQUEmJCTEDBkyxJw9e9YLn6Z4yWtu4+Pjc/13bt26da5jMLe5s/qze7mcghPzm7P8zO2cOXNMvXr1TEBAgImJiTErVqxwO0ZJ+x3CZswlX6MOAAAAAMiGa5wAAAAAwALBCQAAAAAsEJwAAAAAwALBCQAAAAAsEJwAAAAAwALBCQAAAAAsEJwAAAAAwALBCQAAAAAsEJwAAMXO4MGD1bNnT2+XAQCAC8EJAFCkbDZbnrcJEyZoxowZmjdvnlfqe+eddxQTE6OgoCCFhYWpefPmmjJlims/oQ4AyiZfbxcAAChbjh075nq8ZMkSjR8/XnFxca5tQUFBCgoK8kZpmjt3rkaNGqXXX39d7du3V1pamnbu3Kldu3Z5pR4AQPFBxwkAUKQiIyNdt9DQUNlsNrdtQUFB2bo6HTp00GOPPaZRo0apYsWKioiI0DvvvKOUlBQNGTJEwcHBqlevnj777DO399q1a5fuuOMOBQUFKSIiQvfff79OnTqVa22ffPKJ+vTpo6FDh6pevXq67rrr1L9/f02aNEmSNGHCBM2fP18ff/yxq0O2fv16SdLhw4fVp08fhYWFqVKlSurRo4cOHDjgOnbWZ5o4caLCw8MVEhKi4cOHKz093WNzCwAoPAQnAECJMH/+fFWpUkVbtmzRY489pkceeUS9e/dW27ZttWPHDt1+++26//77lZqaKkk6c+aMbrvtNjVv3lzbtm3T559/ruPHj6tPnz65vkdkZKQ2b96sgwcP5rj/ySefVJ8+fdS1a1cdO3ZMx44dU9u2bZWRkaEuXbooODhYX3/9tb799lsFBQWpa9eubsFo7dq1+vnnn7V+/XotWrRIy5Yt08SJEz07UQCAQkFwAgCUCDExMfrnP/+p+vXra+zYsQoICFCVKlU0bNgw1a9fX+PHj9cff/yhnTt3SpLefPNNNW/eXJMnT1ajRo3UvHlzzZ07V+vWrdOvv/6a43s8//zzCgsLU+3atdWwYUMNHjxYS5culcPhkOQ8jTAwMFB2u93VIfP399eSJUvkcDj07rvvqmnTprr22mv1n//8R4cOHXJ1pCTJ399fc+fO1XXXXadu3brphRde0Ouvv+46PgCg+CI4AQBKhOuvv9712MfHR5UrV1bTpk1d2yIiIiRJJ06ckCT9+OOPWrduneuaqaCgIDVq1EiStH///hzfo1q1atq0aZN++uknPfHEE7pw4YIGDRqkrl275hlufvzxR+3bt0/BwcGu96pUqZLOnz/v9l4xMTEqX76863mbNm2UnJysw4cPF2BGAABFicUhAAAlgp+fn9tzm83mts1ms0mSK+AkJyere/fumjp1arZjVatWLc/3atKkiZo0aaJHH31Uw4cP1y233KINGzaoY8eOOY5PTk5WixYttGDBgmz7wsPD8/5gAIASgeAEACiVbrjhBn300UeqXbu2fH0L/s9d48aNJUkpKSmSnKfbZWZmZnuvJUuWqGrVqgoJCcn1WD/++KPOnTunwMBASdLmzZsVFBSk6OjoAtcHACganKoHACiVRowYodOnT6t///7aunWr9u/fry+++EJDhgzJFnyyPPLII3rxxRf17bff6uDBg9q8ebMGDhyo8PBwtWnTRpJUu3Zt7dy5U3FxcTp16pQyMjI0YMAAValSRT169NDXX3+t+Ph4rV+/Xo8//rh+//131/HT09M1dOhQ7dmzR6tXr9bzzz+vkSNHqlw5/jkGgOKOv6kBAKVSVFSUvv32W2VmZur2229X06ZNNWrUKIWFheUaVDp37qzNmzerd+/eatCgge655x4FBARo7dq1qly5siRp2LBhatiwoVq2bKnw8HB9++23Kl++vDZu3KiaNWuqV69euvbaazV06FCdP3/erQPVqVMn1a9fX7feeqv69u2ru+66SxMmTCiK6QAAXCWbMcZ4uwgAAEq7wYMH68yZM1qxYoW3SwEAFAAdJwAAAACwQHACAAAAAAucqgcAAAAAFug4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWCA4AQAAAIAFghMAAAAAWPj/7hTVzCo8/qAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_reshaped, label='Actual')\n",
    "plt.plot(predictions, label='Predicted', color='red')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('v_vel')\n",
    "plt.title('Actual vs Predicted v_vel')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f82724df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum velocity: 51.3\n",
      "Index of maximum velocity: 75\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the maximum velocity\n",
    "max_index = velocity_dataset['v_vel'].idxmax()\n",
    "\n",
    "# Find the maximum velocity itself\n",
    "max_velocity = velocity_dataset.loc[max_index, 'v_vel']\n",
    "\n",
    "print(f\"Maximum velocity: {max_velocity}\")\n",
    "print(f\"Index of maximum velocity: {max_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "55bda514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted velocities for next 5 time steps using autoregressive approach:\n",
      "[[ 7.573]\n",
      " [14.019]\n",
      " [11.839]\n",
      " [48.795]\n",
      " [83.436]]\n"
     ]
    }
   ],
   "source": [
    "# Number of future time steps to predict\n",
    "n_steps = 5\n",
    "\n",
    "# Initialize an array to store predicted velocities\n",
    "predicted_velocities = []\n",
    "\n",
    "# Start with the last known sequence from the test data\n",
    "current_input = X_test[-1].reshape(1, 1, X_test.shape[2])\n",
    "\n",
    "# Perform autoregressive prediction for n_steps\n",
    "for _ in range(n_steps):\n",
    "    current_pred = lstm_model.predict(current_input, verbose=0)\n",
    "    predicted_velocities.append(current_pred[0])  # Append the current prediction\n",
    "    \n",
    "    # Update current input with the new prediction\n",
    "    current_input = np.array([np.append(current_input[0][0][1:], current_pred[0])]).reshape(1, 1, -1)\n",
    "\n",
    "# Convert predictions to the correct shape\n",
    "predicted_velocities = np.array(predicted_velocities).reshape(-1, 1)\n",
    "\n",
    "# Print or use the predicted velocities\n",
    "print(\"Predicted velocities for next 5 time steps using autoregressive approach:\")\n",
    "print(predicted_velocities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
